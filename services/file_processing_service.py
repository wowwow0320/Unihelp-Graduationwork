# services/file_processing_service.py

import os
import re
from pathlib import Path
from pdf2docx import Converter
from llama_parse import LlamaParse
from docx import Document
from docx.oxml.text.paragraph import CT_P
from docx.oxml.table import CT_Tbl
from docx.text.paragraph import Paragraph
from docx.table import Table
from bs4 import BeautifulSoup
import pandas as pd
import io
from core.config import settings

class FileProcessingService:
    def __init__(self, upload_dir: str = "uploads"):
        self.upload_dir = Path(upload_dir)
        self.upload_dir.mkdir(exist_ok=True)

    def _pdf_to_docx(self, pdf_path: str, docx_path: str):
        try:
            cv = Converter(str(pdf_path))
            cv.convert(str(docx_path))
            cv.close()
            print(f"ğŸ“„ PDF â†’ DOCX ë³€í™˜ ì™„ë£Œ: {docx_path}")
        except Exception as e:
            raise Exception(f"pdf_to_docx ì˜¤ë¥˜: {e}")

    def _pdf_to_markdown(self, pdf_path: str, md_path: str):
        parsing_instruction = (
            "ë³¸ë¬¸ê³¼ í‘œë¥¼ êµ¬ë¶„í•´ ì£¼ì„¸ìš”.\n"
            "- í‘œì˜ ì²« í–‰ì´ ì—¬ëŸ¬ ì¤„ë¡œ êµ¬ì„±ë˜ì–´ ìˆë‹¤ë©´, ì´ë¥¼ í—¤ë”ë¡œ ê°„ì£¼í•˜ê³  ë³‘í•©í•´ í•˜ë‚˜ì˜ í—¤ë”ë¡œ ë§Œë“¤ì–´ì£¼ì„¸ìš”.\n"
            "- í‘œëŠ” ì •í™•íˆ html í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•´ì£¼ì„¸ìš”.\n"
            "- í‘œì˜ í—¤ë”ëŠ” ë°˜ë“œì‹œ ê° ì—´ì— ë§ì¶° ë¶„ë¦¬í•´ì£¼ì„¸ìš”.\n"
            "- ì¤„ ë°”ê¿ˆ íƒœê·¸(<br/>)ëŠ” ì ˆëŒ€ ì‚¬ìš©í•˜ì§€ ë§ê³ , ì—¬ëŸ¬ ì¡°ê±´ì´ ìˆëŠ” ì…€ì€ ìŠ¬ë˜ì‹œ(/) ë˜ëŠ” ì‰¼í‘œ(,)ë¡œ êµ¬ë¶„í•´ì£¼ì„¸ìš”.\n"
            "- ë³‘í•©ëœ ì…€ì€ í•´ë‹¹ ì—´ì— ë§ì¶° ë°˜ë³µ ì‚½ì…í•´ì£¼ì„¸ìš”.\n"
            "- ì—´ ìˆ˜ê°€ ë¶ˆê· í˜•í•œ í–‰ì€ ë¬´ì¡°ê±´ í—¤ë” ì—´ ìˆ˜ì— ë§ì¶° ì •ë ¬í•´ì£¼ì„¸ìš”.\n"
            "- ìš”ì•½ì´ë‚˜ ì„¤ëª…ì€ ì ˆëŒ€ í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”.\n"
        )
        parser = LlamaParse(api_key=settings.LLAMA_CLOUD_API_KEY, result_type="markdown", parsing_instruction=parsing_instruction, verbose=True)
        try:
            documents = parser.load_data(str(pdf_path))
            with open(md_path, "w", encoding="utf-8") as f:
                f.write(documents[0].text)
            print(f"ğŸ“„ PDF â†’ Markdown ë³€í™˜ ì™„ë£Œ: {md_path}")
        except Exception as e:
            raise Exception(f"pdf_to_markdown ì˜¤ë¥˜: {e}")

    def _docx_tables_to_html(self, docx_path: str, html_path: str):
        doc = Document(docx_path)
        full_parts = []
        for table in doc.tables:
            html_table = "<table border='1'>\n"
            for row in table.rows:
                html_table += "  <tr>\n"
                for cell in row.cells:
                    cell_text = "<br>".join(p.text.strip() for p in cell.paragraphs if p.text.strip())
                    html_table += f"    <td>{cell_text}</td>\n"
                html_table += "  </tr>\n"
            html_table += "</table>\n"
            full_parts.append(html_table)
        
        soup = BeautifulSoup("\n".join(full_parts), "html.parser")
        with open(html_path, "w", encoding="utf-8") as f:
            f.write(soup.prettify())
        print(f"ğŸ“„ DOCX â†’ HTML(Tables) ë³€í™˜ ì™„ë£Œ: {html_path}")

    def _html_tables_to_text(self, html_path: str, txt_path: str):
        try:
            with open(html_path, 'r', encoding='utf-8') as f:
                content = f.read()
        except FileNotFoundError:
            raise Exception(f"ì…ë ¥ íŒŒì¼ '{html_path}'ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

        blocks = content.split('\n# ')[1:] if '\n# ' in content else [content]
        final_sentences = []
        for i, block in enumerate(blocks):
            block = block.strip()
            if not block: continue
            parts = block.split('\n', 1)
            title = parts[0].strip() if len(parts) > 1 else f"í…Œì´ë¸” {i+1}"
            table_html = parts[1].strip() if len(parts) > 1 else block
            try:
                df_list = pd.read_html(io.StringIO(table_html), header=0, encoding='utf-8')
                if not df_list: continue
                df = df_list[0]
                if df.iloc[0].astype(str).str.contains('ëŒ€ í•™').any():
                    new_header = df.iloc[0]
                    df = df[1:]
                    df.columns = [f"{col.split('.')[0]} {val}" if 'Unnamed' not in str(col) else val for col, val in new_header.items()]
                for _, row in df.iterrows():
                    row_data = ", ".join([f"{col}: {val}" for col, val in row.items() if pd.notna(val)])
                    final_sentences.append(f"ì œëª©: {title}, {row_data}")
            except Exception as e:
                print(f"âš ï¸ {i+1}ë²ˆì§¸ í…Œì´ë¸” ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ (ê±´ë„ˆëœë‹ˆë‹¤): {e}")
        
        with open(txt_path, 'w', encoding='utf-8') as f:
            f.write('\n'.join(final_sentences))
        print(f"ğŸ“„ HTML â†’ TXT(RAG) ë³€í™˜ ì™„ë£Œ: {txt_path}")

    def process_pipeline(self, pdf_path: str) -> tuple[str, str]:
        base_name = Path(pdf_path).stem
        
        docx_path = self.upload_dir / f"{base_name}.docx"
        self._pdf_to_docx(pdf_path, docx_path)
        
        md_path = self.upload_dir / f"{base_name}.md"
        self._pdf_to_markdown(pdf_path, md_path)
        
        html_path = self.upload_dir / f"{base_name}.html"
        self._docx_tables_to_html(docx_path, html_path)
        
        txt_path = self.upload_dir / f"{base_name}_rag.txt"
        self._html_tables_to_text(html_path, txt_path)
            
        return str(md_path), str(txt_path)

file_processor = FileProcessingService()